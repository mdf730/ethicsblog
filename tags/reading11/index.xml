<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reading11 on Matthew Fabian</title>
    <link>https://mdf730.github.io/ethicsblog/tags/reading11/</link>
    <description>Recent content in Reading11 on Matthew Fabian</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 Nov 2017 14:29:37 -0400</lastBuildDate>
    
	<atom:link href="https://mdf730.github.io/ethicsblog/tags/reading11/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Artificial Intelligence</title>
      <link>https://mdf730.github.io/ethicsblog/post/ai/</link>
      <pubDate>Sun, 12 Nov 2017 14:29:37 -0400</pubDate>
      
      <guid>https://mdf730.github.io/ethicsblog/post/ai/</guid>
      <description>Artificial Intelligence falls into two categories of two options; narrow or general, and strong or weak. Narrow AI functions well when working on an individual task (i.e. playing chess), while general AI is focused on reasoning with any sort of problem. Weak AI is focused on mimicking human intelligence by the measure of how correct the output is, while strong AI focuses on mimicking human intelligence in terms of how the machine “thinks” or processes data.</description>
    </item>
    
  </channel>
</rss>